{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77fd967e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. tool name: wikipedia_search_tool;  tool goal: Searches for a Wikipedia article summary by query string.;  tool parameters: {'query': {'type': 'string', 'description': 'Search keywords for the Wikipedia article.'}, 'sentences': {'type': 'integer', 'description': 'Number of sentences in the summary.', 'default': 5}} \n",
      "2. tool name: wikipedia_search_tool;  tool goal: Searches for a Wikipedia article summary by query string.;  tool parameters: {'query': {'type': 'string', 'description': 'Search keywords for the Wikipedia article.'}, 'sentences': {'type': 'integer', 'description': 'Number of sentences in the summary.', 'default': 5}} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "wikipedia_tool_def = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"wikipedia_search_tool\",\n",
    "        \"description\": \"Searches for a Wikipedia article summary by query string.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Search keywords for the Wikipedia article.\"\n",
    "                },\n",
    "                \"sentences\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"Number of sentences in the summary.\",\n",
    "                    \"default\": 5\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "tools = [wikipedia_tool_def, wikipedia_tool_def]\n",
    "\n",
    "tools_ = \"\"\n",
    "\n",
    "for i, tool in enumerate(tools):\n",
    "    name = f\"tool name: {tool['function']['name']}; \"\n",
    "    description = f\"tool goal: {tool['function']['description']}; \"\n",
    "    parameters = f\"tool parameters: {tool['function']['parameters']['properties']}\"\n",
    "    \n",
    "    tools_ += f\"{i+1}. {name} {description} {parameters} \\n\"\n",
    "\n",
    "print(tools_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ea654c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/padeiroc/ai_project/agents/.venv/bin/python: No module named uv\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "uv add torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217dadb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'diffusers'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m login\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi_base_url\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ApiConfig\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdiffusers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StableDiffusionPipeline, AutoPipelineForText2Image, DiffusionPipeline\n\u001b[32m     11\u001b[39m load_dotenv(override=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     12\u001b[39m hf_token = os.getenv(ApiConfig.HUGGING_FACE_API_TOKEN)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'diffusers'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "# --- Third-party ---\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "from utils.api_base_url import ApiConfig\n",
    "from diffusers import StableDiffusionPipeline, AutoPipelineForText2Image, DiffusionPipeline\n",
    "\n",
    "load_dotenv(override=True)\n",
    "hf_token = os.getenv(ApiConfig.HUGGING_FACE_API_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e784b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Decision Tree: Which Pipeline to Use?\n",
    "# ```\n",
    "# Do you know the exact model family?\n",
    "# ├─ YES, it's Stable Diffusion v1.x/v2.x\n",
    "# │  └─> Use StableDiffusionPipeline (most explicit control)\n",
    "# │\n",
    "# ├─ YES, it's FLUX\n",
    "# │  └─> Use FluxPipeline (FLUX-specific optimizations)\n",
    "# │\n",
    "# ├─ NO, could be anything\n",
    "# │  └─> Use DiffusionPipeline (maximum flexibility)\n",
    "# │\n",
    "# └─ Want task-specific features for text-to-image?\n",
    "#    └─> Use AutoPipelineForText2Image (clear intent + optimizations)\n",
    "\n",
    "class ImageGenerator:\n",
    "    \n",
    "    def __init__(self, model_id:str = \"stabilityai/stable-diffusion-xl-base-1.0\",torch_dtype=torch.float16):\n",
    "        login(hf_token, add_to_git_credential=True)\n",
    "        self.torch_dtype = torch_dtype\n",
    "        self.model_id = model_id\n",
    "        \n",
    "        self.pipeline = AutoPipelineForText2Image.from_pretrained(\n",
    "                    self.model_id,\n",
    "                    self.torch_dtype,\n",
    "                    variant=\"fp16\")\n",
    "    \n",
    "    def memory_optimizer(self, optimizer_type:str=\"offload\"):\n",
    "        if optimizer_type == \"offload\":\n",
    "            self.pipeline.enable_model_cpu_offload()  # Aggressive memory saving\n",
    "            \n",
    "        elif optimizer_type == \"vae_slicing\":\n",
    "            self.pipeline.enable_vae_slicing()         # Reduce memory for VAE\n",
    "            \n",
    "        else:\n",
    "            self.pipeline.enable_attention_slicing()   # Reduce memory for attention\n",
    "    \n",
    "    def generate(self, prompt: str=\"\", negative_prompt: str = \"\", size:dict = (512, 512),  pipeline_type:str =\"text2Image\", model_id:str = None, device:str=\"cuda\"):\n",
    "        \n",
    "        if pipeline_type == \"text2Image\":\n",
    "            \n",
    "            image =  self.pipeline(\n",
    "                prompt = prompt,\n",
    "                negative_prompt = negative_prompt,\n",
    "                num_inference_steps = 40,\n",
    "                guidance_scale = 7.5,\n",
    "                height = size[0],\n",
    "                width = size[1]\n",
    "                ).to(device)\n",
    "            \n",
    "            return image[0]\n",
    "            \n",
    "        if pipeline_type == \"diffusion\":\n",
    "            \n",
    "            if model_id is None:\n",
    "                model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "            # Explicitly for Stable Diffusion v1.x/v2.x\n",
    "            self.pipeline = DiffusionPipeline.from_pretrained(\n",
    "                model_id,\n",
    "                torch_dtype=torch.float16,\n",
    "                safety_checker=None  # Can disable safety checker\n",
    "            )\n",
    "            self.pipeline = self.pipeline.to(\"cuda\")\n",
    "\n",
    "            # Classic SD interface\n",
    "            image = self.pipeline(\n",
    "                prompt=prompt,\n",
    "                negative_prompt = negative_prompt,\n",
    "                num_inference_steps = 50,\n",
    "                guidance_scale = 7.5,\n",
    "                height = size[0],\n",
    "                width = size[1]\n",
    "            )\n",
    "            return image[0]\n",
    "    \n",
    "        if pipeline_type == \"stableDiffusion\":\n",
    "            \n",
    "            if model_id is None:\n",
    "                model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "                \n",
    "            # Explicitly for Stable Diffusion v1.x/v2.x\n",
    "            self.pipeline = StableDiffusionPipeline.from_pretrained(\n",
    "                model_id,\n",
    "                torch_dtype=torch.float16,\n",
    "                safety_checker=None  # Can disable safety checker\n",
    "            )\n",
    "            self.pipeline = self.pipeline.to(\"cuda\")\n",
    "\n",
    "            # Classic SD interface\n",
    "            image = self.pipeline(\n",
    "                prompt=prompt,\n",
    "                negative_prompt = negative_prompt,\n",
    "                num_inference_steps = 50,\n",
    "                guidance_scale = 7.5,\n",
    "                height = size[0],\n",
    "                width = size[1]\n",
    "            )\n",
    "            return image[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feaa906c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-17-Oct\n",
      "2025-10-17 22:37:18.739989\n",
      "image_2025_10_17223718\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "print(datetime.now().strftime(\"%Y-%m-%d-%h\"))\n",
    "print(datetime.now())\n",
    "\n",
    "dt = datetime.now()\n",
    "\n",
    "hour = dt.hour\n",
    "minute = dt.minute\n",
    "second = dt.second\n",
    "\n",
    "name = f\"image_{dt.strftime(\"%Y_%m_%d\")}{dt.hour}{dt.minute}{dt.second}\"\n",
    "\n",
    "print(name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53228ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "def load_and_prepare_data( csv_path: str=os.path.join(os.getcwd(),\"dataset/coffee_sales.csv\")) -> pd.DataFrame:\n",
    "    \"\"\"Load CSV and derive date parts commonly used in charts.\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Be tolerant if 'date' exists\n",
    "    if \"date\" in df.columns:\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "        df[\"quarter\"] = df[\"date\"].dt.quarter\n",
    "        df[\"month\"] = df[\"date\"].dt.month\n",
    "        df[\"year\"] = df[\"date\"].dt.year\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e46775",
   "metadata": {},
   "outputs": [],
   "source": [
    "uv add --active matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d24a4b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# import matplotlib.pyplot as plt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# Assuming df is already loaded\n",
    "df = load_and_prepare_data()\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'], format='%m/%d/%y')\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter('cash_type', 'price', data=df, hue='coffee_name', marker='', s=50, alpha=0.5, c='b', edgecolor='red')\n",
    "plt.title('Coffee Price by Type and Name', fontsize=18)\n",
    "plt.xlabel('Cash Type', fontsize=14)\n",
    "plt.ylabel('Price', fontsize=14)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.savefig('/home/padeiroc/ai_project/data_processing_agent/out_puts/generate_chart_2025_10_1817109.png', dpi=300)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mult-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
